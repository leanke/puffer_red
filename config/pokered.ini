[base]
package = pokered
env_name = pokered
policy_name = PokemonRed
rnn_name = PokemonRedLSTM

[vec]
num_envs = 16
batch_size = auto

[env]
num_envs = 28
rom_path = "./pokemon_red.gb"
state_path = "pokered/states/new_start.ss1"
; headless = False
headless = True
frameskip = 4
max_episode_length = 20480
; 16384
full_reset = True
; log_interval = 256
stream_enabled = True
stream_interval = 400
stream_user = "leanke",
stream_color = "#800080",
stream_extra = ""

; BLUE = "#0000FF"
; GREEN = "#00A36C"
; RED = "#FF0000"
; PURPLE = "#800080"
; PINK = "#FF00FF"
; YELLOW = "#DAEE01"

; possibly epoch = 1? need to test for speed
; Use bptt to manip batchsize (num_envs * bptt = batchsize)
; possibly try 256 for batchsize 32768 (512 is for 65536)
[train]
total_timesteps = 1_000_000_000
update_epochs = 1
bptt_horizon = 512
compile = False
compile_mode = reduce-overhead
compile_fullgraph = False
anneal_lr =  True
device = cuda

gamma = 0.9815646031317408
; 0.0014073
learning_rate = 0.0014073
max_minibatch_size = 32768
minibatch_size = 2048
optimizer = muon
precision = float32

adam_beta1 = 0.9562162369235768
adam_beta2 = 0.9985481830898764
adam_eps = 0.00000177221688560271
clip_coef = 0.01
ent_coef = 0.04670828890217251
gae_lambda = 0.9139269293303732
max_grad_norm = 0.8229705929037459
prio_alpha = 0.7710711644328326
prio_beta0 = 0.9411894352769828
vf_clip_coef = 0.1
vf_coef = 3.095843847555002
vtrace_c_clip = 1.0266069962245616
vtrace_rho_clip = 1.7049230821842278





; total_timesteps = 1_000_000_000
; ; possibly epoch = 1? need to test for speed
; update_epochs = 3
; ; Use bptt to manip batchsize (num_envs * bptt = batchsize)
; ; possibly try 256 for batchsize 32768 (512 is for 65536)
; bptt_horizon = 512
; compile = False
; compile_mode = reduce-overhead
; compile_fullgraph = False
; anneal_lr =  False
; device = cuda
; ; gamma = 0.998
; ; learning_rate = 0.005
; ; minibatch_size = 2048
; ; torch_deterministic = true


[sweep]
method = Protein 
metric = episode_return
goal = maximize
downsample = 10

[sweep.train.learning_rate]
distribution = log_normal
min = 0.00001
mean = 0.01
max = 0.1
scale = 0.5

[sweep.train.ent_coef]
distribution = log_normal
min = 0.00001
mean = 0.01
max = 0.2
scale = auto

[sweep.train.gamma]
distribution = logit_normal
min = 0.8
mean = 0.98
max = 0.9999
scale = auto

[sweep.train.gae_lambda]
distribution = logit_normal
min = 0.6
mean = 0.95
max = 0.995
scale = auto

[sweep.train.update_epochs]
distribution = int_uniform
min = 1
max = 4
mean = 1
scale = 2.0




#[sweep.vec.num_envs]
#distribution = uniform_pow2
#min = 1
#max = 16
#mean = 8
#scale = auto

; # TODO =  Elim from base
; [sweep.train.total_timesteps]
; distribution = log_normal
; min = 5e7
; max = 1e10
; mean = 1e8
; scale = time

; [sweep.train.bptt_horizon]
; distribution = uniform_pow2
; min = 16
; max = 64
; mean = 64
; scale = auto

; [sweep.train.minibatch_size]
; distribution = uniform_pow2
; min = 256
; max = 4096
; mean = 2048
; scale = auto




